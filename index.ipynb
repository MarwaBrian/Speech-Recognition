{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d47b649d7039278",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8664e73e3ec7ce7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T09:02:05.382524400Z",
     "start_time": "2024-02-05T09:02:04.611008700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading the necessary libraries\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import librosa\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3fbda5f5b5b24a57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T09:02:05.463525300Z",
     "start_time": "2024-02-05T09:02:05.387527800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>File Name</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>File Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry_bcbcf8a2</td>\n",
       "      <td>OAF_back_angry.wav</td>\n",
       "      <td>angry</td>\n",
       "      <td>dataverse_files\\OAF_back_angry.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust_52cdd1b9</td>\n",
       "      <td>OAF_back_disgust.wav</td>\n",
       "      <td>disgust</td>\n",
       "      <td>dataverse_files\\OAF_back_disgust.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fear_adacc67f</td>\n",
       "      <td>OAF_back_fear.wav</td>\n",
       "      <td>fear</td>\n",
       "      <td>dataverse_files\\OAF_back_fear.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy_5d47cbfb</td>\n",
       "      <td>OAF_back_happy.wav</td>\n",
       "      <td>happy</td>\n",
       "      <td>dataverse_files\\OAF_back_happy.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral_13dc91d7</td>\n",
       "      <td>OAF_back_neutral.wav</td>\n",
       "      <td>neutral</td>\n",
       "      <td>dataverse_files\\OAF_back_neutral.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ps_cb173731</td>\n",
       "      <td>OAF_back_ps.wav</td>\n",
       "      <td>ps</td>\n",
       "      <td>dataverse_files\\OAF_back_ps.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sad_0585a8cc</td>\n",
       "      <td>OAF_back_sad.wav</td>\n",
       "      <td>sad</td>\n",
       "      <td>dataverse_files\\OAF_back_sad.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>angry_9271fd76</td>\n",
       "      <td>OAF_bar_angry.wav</td>\n",
       "      <td>angry</td>\n",
       "      <td>dataverse_files\\OAF_bar_angry.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>disgust_f8c0ebfb</td>\n",
       "      <td>OAF_bar_disgust.wav</td>\n",
       "      <td>disgust</td>\n",
       "      <td>dataverse_files\\OAF_bar_disgust.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fear_42e1a9de</td>\n",
       "      <td>OAF_bar_fear.wav</td>\n",
       "      <td>fear</td>\n",
       "      <td>dataverse_files\\OAF_bar_fear.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID             File Name  Emotion  \\\n",
       "0    angry_bcbcf8a2    OAF_back_angry.wav    angry   \n",
       "1  disgust_52cdd1b9  OAF_back_disgust.wav  disgust   \n",
       "2     fear_adacc67f     OAF_back_fear.wav     fear   \n",
       "3    happy_5d47cbfb    OAF_back_happy.wav    happy   \n",
       "4  neutral_13dc91d7  OAF_back_neutral.wav  neutral   \n",
       "5       ps_cb173731       OAF_back_ps.wav       ps   \n",
       "6      sad_0585a8cc      OAF_back_sad.wav      sad   \n",
       "7    angry_9271fd76     OAF_bar_angry.wav    angry   \n",
       "8  disgust_f8c0ebfb   OAF_bar_disgust.wav  disgust   \n",
       "9     fear_42e1a9de      OAF_bar_fear.wav     fear   \n",
       "\n",
       "                              File Path  \n",
       "0    dataverse_files\\OAF_back_angry.wav  \n",
       "1  dataverse_files\\OAF_back_disgust.wav  \n",
       "2     dataverse_files\\OAF_back_fear.wav  \n",
       "3    dataverse_files\\OAF_back_happy.wav  \n",
       "4  dataverse_files\\OAF_back_neutral.wav  \n",
       "5       dataverse_files\\OAF_back_ps.wav  \n",
       "6      dataverse_files\\OAF_back_sad.wav  \n",
       "7     dataverse_files\\OAF_bar_angry.wav  \n",
       "8   dataverse_files\\OAF_bar_disgust.wav  \n",
       "9      dataverse_files\\OAF_bar_fear.wav  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting emotions and placing it in its column\n",
    "\n",
    "def extract_emotion(file_name):\n",
    "    parts = file_name.split('_')\n",
    "    emotion = parts[-1].split('.')[0]\n",
    "    return emotion\n",
    "\n",
    "def create_emotional_dataframe(folder_path):\n",
    "    data = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        emotion = extract_emotion(file_name)\n",
    "        unique_id = f\"{emotion}_{str(uuid.uuid4())[:8]}\"\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        data.append({'ID': unique_id, 'File Name': file_name, 'Emotion': emotion, 'File Path': file_path})\n",
    "        \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "folder_path_wav = r'dataverse_files'\n",
    "\n",
    "emotion_df_wav = create_emotional_dataframe(folder_path_wav)\n",
    "\n",
    "# Display the DataFrame\n",
    "emotion_df_wav.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d51b700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path):\n",
    "    # Load audio file\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    \n",
    "    # Extract MFCCs (Mel-Frequency Cepstral Coefficients)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    \n",
    "    # Calculate pitch\n",
    "    pitches, magnitudes = librosa.piptrack(y=y, sr=sr)\n",
    "    pitch = np.mean(pitches)\n",
    "    \n",
    "    # Calculate energy\n",
    "    energy = np.mean(librosa.feature.rms(y=y))\n",
    "    \n",
    "    # Calculate spectral features\n",
    "    spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
    "    spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr))\n",
    "    spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=y, sr=sr))\n",
    "    \n",
    "    return mfccs, pitch, energy, spectral_centroid, spectral_bandwidth, spectral_contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c4eed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features = []\n",
    "max_length = 0  # Track the maximum length of MFCC arrays\n",
    "\n",
    "for file_path in emotion_df_wav['File Path']:\n",
    "    mfccs, pitch, energy, spectral_centroid, spectral_bandwidth, spectral_contrast = extract_features(file_path)\n",
    "    \n",
    "    # Flatten MFCCs to ensure consistent shape\n",
    "    mfccs_flat = mfccs.flatten()\n",
    "    \n",
    "    # Update max_length if necessary\n",
    "    max_length = max(max_length, mfccs_flat.shape[0])\n",
    "    \n",
    "    # Combine all other features into a single 1D array\n",
    "    features_combined = np.hstack((mfccs_flat, pitch, energy, spectral_centroid, spectral_bandwidth, spectral_contrast))\n",
    "    \n",
    "    audio_features.append(features_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d90a3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2800, 3697)\n",
      "[[-616.8069458  -572.98529053 -487.13040161 ...    0.\n",
      "     0.            0.        ]\n",
      " [-686.6395874  -612.41943359 -562.41546631 ...    0.\n",
      "     0.            0.        ]\n",
      " [-675.70111084 -673.92712402 -634.75012207 ...    0.\n",
      "     0.            0.        ]\n",
      " [-544.85992432 -491.78671265 -463.30151367 ...    0.\n",
      "     0.            0.        ]\n",
      " [-765.62237549 -760.74121094 -764.26812744 ...    0.\n",
      "     0.            0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Pad MFCC arrays to ensure consistent shapes\n",
    "max_length = max(len(features) for features in audio_features)\n",
    "\n",
    "padded_audio_features = []\n",
    "for features in audio_features:\n",
    "    # Calculate the amount of padding needed\n",
    "    padding_width = max_length - len(features)\n",
    "    # Pad the features array with zeros to match the maximum length\n",
    "    padded_features = np.pad(features, ((0, padding_width)), mode='constant')\n",
    "    padded_audio_features.append(padded_features)\n",
    "\n",
    "# Convert the list of arrays to a 2D NumPy array\n",
    "padded_audio_features_array = np.array(padded_audio_features)\n",
    "\n",
    "print(padded_audio_features_array.shape)  # Display the shape of the padded array\n",
    "print(padded_audio_features_array[:5])     # Display the first 5 elements of the padded array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "12161ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (2240, 3697)\n",
      "Validation data shape: (280, 3697)\n",
      "Testing data shape: (280, 3697)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and temporary sets\n",
    "train_data, temp_data = train_test_split(padded_audio_features_array, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the temporary data into validation and testing sets\n",
    "validation_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "\n",
    "# Display the shapes of the datasets\n",
    "print(\"Training data shape:\", train_data.shape)\n",
    "print(\"Validation data shape:\", validation_data.shape)\n",
    "print(\"Testing data shape:\", test_data.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
